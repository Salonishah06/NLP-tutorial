{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO7J6d+9O8eTJZYizRr5DEk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AWk7o44mbmR9","executionInfo":{"status":"ok","timestamp":1666941126637,"user_tz":-330,"elapsed":2415,"user":{"displayName":"Saloni Shah","userId":"00639937033033395583"}},"outputId":"8feeda85-86cb-47ad-f247-cffcf1a28ac1"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]}],"source":["import nltk\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.stem import SnowballStemmer, LancasterStemmer,  PorterStemmer,WordNetLemmatizer\n","from nltk.corpus import wordnet\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('punkt')\n","nltk.download('omw-1.4')\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["# word tokenization\n","data = \"All work and no play makes jack a dull boy, all work and no play\"\n","tokens = word_tokenize(data.lower())\n","print(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KL3gfYvUbzKS","executionInfo":{"status":"ok","timestamp":1666941153772,"user_tz":-330,"elapsed":5,"user":{"displayName":"Saloni Shah","userId":"00639937033033395583"}},"outputId":"9e433d36-8db8-444a-efd7-4d9eaf48dc9d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["['all', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', ',', 'all', 'work', 'and', 'no', 'play']\n"]}]},{"cell_type":"code","source":["# sentence tokenization\n","print(sent_tokenize(\"I was going home when she rung. It was a surprise.\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cMrr_ptb2mZ","executionInfo":{"status":"ok","timestamp":1666941167165,"user_tz":-330,"elapsed":407,"user":{"displayName":"Saloni Shah","userId":"00639937033033395583"}},"outputId":"c3a8eb3a-0a3f-4298-9937-3559be0d3a05"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['I was going home when she rung.', 'It was a surprise.']\n"]}]},{"cell_type":"code","source":["porter = PorterStemmer()\n","porter.stem('going')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Mn66GIu-b53m","executionInfo":{"status":"ok","timestamp":1666941182261,"user_tz":-330,"elapsed":7,"user":{"displayName":"Saloni Shah","userId":"00639937033033395583"}},"outputId":"8c042837-0f67-4e12-c890-57396a1340a7"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'go'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["plurals = ['universal','universe','university']\n","singles = [porter.stem(plural) for plural in plurals]\n","print(' '.join(singles))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bZd63lOxb9xm","executionInfo":{"status":"ok","timestamp":1666941194382,"user_tz":-330,"elapsed":5,"user":{"displayName":"Saloni Shah","userId":"00639937033033395583"}},"outputId":"416f23e6-0dd7-4565-e9f5-bdbc7ce0d75b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["univers univers univers\n"]}]},{"cell_type":"code","source":["plurals = ['alumnus','alumni']\n","singles = [porter.stem(plural) for plural in plurals]\n","print(' '.join(singles))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qc1s4bH_cAvm","executionInfo":{"status":"ok","timestamp":1666941205299,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saloni Shah","userId":"00639937033033395583"}},"outputId":"d90d3d8b-8d68-46ad-e8ed-ab98266d142e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["alumnu alumni\n"]}]},{"cell_type":"code","source":["text = \"Here you can find activities to practise your reading skills. Reading will help you to improve your understanding of the language and build your vocabulary.The self-study lessons in this section are written and organised according to the levels of the Common European Framework of Reference for languages (CEFR). There are different types of texts and interactive exercises that practise the reading skills you need to do well in your studies, to get ahead at work and to communicate in English in your free time.Take our free online English test to find out which level to choose. Select your level, from beginner (CEFR level A1) to advanced (CEFR level C1), and improve your reading skills at your own speed, whenever it's convenient for you.\""],"metadata":{"id":"KuoElxO_cDeN","executionInfo":{"status":"ok","timestamp":1666941225382,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saloni Shah","userId":"00639937033033395583"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["tokenized_eu = word_tokenize(text)\n","porter_eu = [porter.stem(word) for word in tokenized_eu]\n","print(f\" PorterStemmer: {100*round(len(''.join(porter_eu))/len(''.join(word_tokenize(text))),3)}%\")\n","\n","snowball = SnowballStemmer(language='english')\n","porter_eu = [snowball.stem(word) for word in tokenized_eu]\n","print(f\" SnowballStemmer: {100*round(len(''.join(porter_eu))/len(''.join(word_tokenize(text))),3)}%\")\n","\n","lanc = LancasterStemmer()\n","porter_eu = [lanc.stem(word) for word in tokenized_eu]\n","print(f\" LancasterStemmerr: {100*round(len(''.join(porter_eu))/len(''.join(word_tokenize(text))),3)}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qJxh0MLtcIP1","executionInfo":{"status":"ok","timestamp":1666941240446,"user_tz":-330,"elapsed":365,"user":{"displayName":"Saloni Shah","userId":"00639937033033395583"}},"outputId":"a3e99891-ec04-4212-a33a-d8cc81fd04c0"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":[" PorterStemmer: 88.4%\n"," SnowballStemmer: 88.9%\n"," LancasterStemmerr: 77.5%\n"]}]},{"cell_type":"code","source":["nltk.download('wordnet')\n","porter = PorterStemmer()\n","lemmatizer = WordNetLemmatizer()\n","print(f\" better\\n Stemming: {porter.stem('better')}\\n Lemmatization: { lemmatizer.lemmatize('better', pos ='a')}\" )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a6eSFxUscLz-","executionInfo":{"status":"ok","timestamp":1666941619481,"user_tz":-330,"elapsed":2414,"user":{"displayName":"Saloni Shah","userId":"00639937033033395583"}},"outputId":"6e06efd8-91f2-43ee-9474-e612bfffc0f0"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":[" better\n"," Stemming: better\n"," Lemmatization: good\n"]}]},{"cell_type":"code","source":["sentence = \"There are mistakes\"\n","print(f'Sentence: {sentence}')\n","\n","word_list = nltk.word_tokenize(sentence)\n","print(f'word_list: {word_list}')\n","\n","lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n","print(f'Lemmatization: {lemmatized_output}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oi2vgPCicPDN","executionInfo":{"status":"ok","timestamp":1666941665521,"user_tz":-330,"elapsed":6,"user":{"displayName":"Saloni Shah","userId":"00639937033033395583"}},"outputId":"06ed722a-9005-4baf-be2f-53a5248329ba"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence: There are mistakes\n","word_list: ['There', 'are', 'mistakes']\n","Lemmatization: There are mistake\n"]}]},{"cell_type":"code","source":["print(nltk.pos_tag(nltk.word_tokenize(sentence)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yYVUTKYydzp9","executionInfo":{"status":"ok","timestamp":1666941686750,"user_tz":-330,"elapsed":771,"user":{"displayName":"Saloni Shah","userId":"00639937033033395583"}},"outputId":"eeebe25e-02c5-49d4-83f4-34282f746b75"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["[('There', 'EX'), ('are', 'VBP'), ('mistakes', 'NNS')]\n"]}]},{"cell_type":"code","source":["def get_pos(word):\n","    tag = nltk.pos_tag([word])[0][1][0].upper()\n","    tag_dict = {\"J\": wordnet.ADJ,\n","                \"N\": wordnet.NOUN,\n","                \"V\": wordnet.VERB,\n","                \"R\": wordnet.ADV}\n","    return tag_dict.get(tag, wordnet.NOUN)\n","\n","lemmatizer = WordNetLemmatizer()\n","print( ' '.join([lemmatizer.lemmatize(w, get_pos(w)) for w in nltk.word_tokenize(sentence)]))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1RZkqJXWd4uL","executionInfo":{"status":"ok","timestamp":1666941703751,"user_tz":-330,"elapsed":514,"user":{"displayName":"Saloni Shah","userId":"00639937033033395583"}},"outputId":"03b64f7b-96dd-4879-bfb8-431986e773ec"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["There be mistake\n"]}]},{"cell_type":"code","source":["# importing NLTK libarary stopwords \n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","\n","print(stopwords.words('english'))\n","\n","# random sentecnce with lot of stop words\n","sample_text = \"Oh man, this is pretty cool. We will do more such things.\"\n","text_tokens = word_tokenize(sample_text)\n","\n","tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n","\n","print(text_tokens)\n","print(tokens_without_sw)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s86gA9twd9Fq","executionInfo":{"status":"ok","timestamp":1666942267531,"user_tz":-330,"elapsed":419,"user":{"displayName":"Saloni Shah","userId":"00639937033033395583"}},"outputId":"87431192-55a8-44ff-d8ea-9b9c78b9e291"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n","['Oh', 'man', ',', 'this', 'is', 'pretty', 'cool', '.', 'We', 'will', 'do', 'more', 'such', 'things', '.']\n","['Oh', 'man', ',', 'pretty', 'cool', '.', 'We', 'things', '.']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["import spacy\n","from nltk.tokenize import word_tokenize\n","# loading english language model of spaCy\n","en_model = spacy.load('en_core_web_sm')\n","# gettign the list of default stop words in spaCy english model\n","stopwords = en_model.Defaults.stop_words\n","\n","sample_text = \"Oh man, this is pretty cool. We will do more such things.\"\n","text_tokens = word_tokenize(sample_text)\n","tokens_without_sw= [word for word in text_tokens if not word in stopwords]\n","\n","print(text_tokens)\n","print(tokens_without_sw)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dv-roSZBgGjc","executionInfo":{"status":"ok","timestamp":1666942300834,"user_tz":-330,"elapsed":8970,"user":{"displayName":"Saloni Shah","userId":"00639937033033395583"}},"outputId":"4538cb88-7f9a-435b-9bce-a05a9f2fdd39"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["['Oh', 'man', ',', 'this', 'is', 'pretty', 'cool', '.', 'We', 'will', 'do', 'more', 'such', 'things', '.']\n","['Oh', 'man', ',', 'pretty', 'cool', '.', 'We', 'things', '.']\n"]}]},{"cell_type":"code","source":["from gensim.parsing.preprocessing import remove_stopwords\n","\n","sample_text = \"Oh man, this is pretty cool. We will do more such things.\"\n","sample_text_NSW = remove_stopwords(text)\n","\n","print(word_tokenize(sample_text))\n","print(word_tokenize(sample_text_NSW))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hJbD6xHqgMs6","executionInfo":{"status":"ok","timestamp":1666942358820,"user_tz":-330,"elapsed":677,"user":{"displayName":"Saloni Shah","userId":"00639937033033395583"}},"outputId":"551dd6df-ba7d-4120-a603-6ca436376a69"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["['Oh', 'man', ',', 'this', 'is', 'pretty', 'cool', '.', 'We', 'will', 'do', 'more', 'such', 'things', '.']\n","['Here', 'activities', 'practise', 'reading', 'skills', '.', 'Reading', 'help', 'improve', 'understanding', 'language', 'build', 'vocabulary.The', 'self-study', 'lessons', 'section', 'written', 'organised', 'according', 'levels', 'Common', 'European', 'Framework', 'Reference', 'languages', '(', 'CEFR', ')', '.', 'There', 'different', 'types', 'texts', 'interactive', 'exercises', 'practise', 'reading', 'skills', 'need', 'studies', ',', 'ahead', 'work', 'communicate', 'English', 'free', 'time.Take', 'free', 'online', 'English', 'test', 'level', 'choose', '.', 'Select', 'level', ',', 'beginner', '(', 'CEFR', 'level', 'A1', ')', 'advanced', '(', 'CEFR', 'level', 'C1', ')', ',', 'improve', 'reading', 'skills', 'speed', ',', 'it', \"'s\", 'convenient', 'you', '.']\n"]}]},{"cell_type":"code","source":["\n","# importing NLTK libarary stopwords \n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","\n","stopwords_default = stopwords.words('english')\n","print(len(stopwords_default))\n","\n","stopwords_default.append('like')\n",", 'marvel', 'ghost'])\n","print(len(stopwords_default))\n","\n","# for adding multiple words\n","stopwords_default.extend(['marvel', 'ghost'])\n","print(len(stopwords_default))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3177uTMAgcpE","executionInfo":{"status":"ok","timestamp":1666942580996,"user_tz":-330,"elapsed":5,"user":{"displayName":"Saloni Shah","userId":"00639937033033395583"}},"outputId":"01404257-c632-481d-e416-a4970c7abe90"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["179\n","180\n","182\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"WYcmdcq4grLU"},"execution_count":null,"outputs":[]}]}